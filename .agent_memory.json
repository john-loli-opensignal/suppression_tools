{
  "project_structure": {
    "database": {
      "path": "data/databases/duck_suppression.db",
      "note": "SINGLE DATABASE ONLY - Assert this path in every connection",
      "assert_check": "assert db_path.endswith('data/databases/duck_suppression.db')"
    },
    "key_directories": {
      "tools": "tools/src/ - Main library code (metrics, outliers, plan, suppress)",
      "data": "data/ - Database and raw data",
      "analysis": "analysis/ - ALL analysis outputs, temp files, reports",
      "scripts": "scripts/ - Executable scripts (build, analysis)",
      "suppressions": "suppressions/rounds/ - Suppression plan CSVs"
    }
  },
  "database_schema": {
    "CRITICAL_PATH": "data/databases/duck_suppression.db",
    "raw_tables": {
      "pattern": "{ds}_preagg with partitions by the_date"
    },
    "cube_tables": {
      "pattern": "{ds}_{win|loss}_{mover|non_mover}_cube",
      "level": "Aggregated at date, state, dma_name, winner, loser",
      "indexes": [
        "date",
        "state",
        "dma",
        "winner",
        "loser"
      ],
      "performance": "Sub-second queries on 6-10GB datasets"
    },
    "census_cube_tables": {
      "pattern": "{ds}_{win|loss}_{mover|non_mover}_census_cube",
      "level": "Aggregated at date, state, dma_name, winner, loser, census_block_id",
      "use_case": "Surgical precision suppression"
    },
    "rolling_views": {
      "pattern": "{ds}_win_{mover|non_mover}_rolling",
      "columns": [
        "the_date",
        "day_of_week",
        "winner",
        "loser",
        "dma",
        "dma_name",
        "state",
        "total_wins",
        "record_count",
        "avg_wins",
        "stddev_wins",
        "n_periods",
        "selected_window",
        "zscore",
        "pct_change",
        "is_first_appearance",
        "is_outlier",
        "appearance_rank"
      ],
      "note": "DOW-aware rolling metrics with TIERED windows (28d preferred, fall back to 14d, then 4d)",
      "dow_mapping": "DuckDB: 0=Monday...6=Sunday (use DAYOFWEEK() for 1=Sunday...7=Saturday)",
      "tiered_logic": {
        "weekday": "Requires 4+ periods minimum (28d, 14d, or 4d)",
        "weekend": "Requires 2+ periods minimum (more lenient due to fewer samples)",
        "selected_window": "Column shows which tier was used (28, 14, 4, or NULL)"
      }
    },
    "enriched_views": {
      "pattern": "{ds}_win_{mover|non_mover}_enriched",
      "purpose": "Combines pair-level + national-level metrics for UI",
      "columns": [
        "All from rolling view",
        "nat_total_wins",
        "nat_market_wins",
        "nat_share_current",
        "nat_mu_share",
        "nat_sigma_share",
        "nat_z_score"
      ],
      "note": "Created on-demand for main.py, filtered to graph window"
    },
    "suppression_tables": {
      "schema": "suppressions",
      "metadata": "suppressions.rounds - Round metadata",
      "plans": "suppressions.{round_name} - Suppression plan records",
      "backup": "Also save to suppressions/rounds/{round_name}.csv"
    }
  },
  "outlier_detection": {
    "hierarchical_levels": [
      "national (ds, mover_ind) - Top level shares",
      "h2h_national (winner, loser) - Pair analysis",
      "state (state, ds, mover_ind) - Geographic patterns",
      "dma (dma_name, winner, loser) - Actionable level",
      "census_block (cb_id, dma, winner, loser) - Surgical precision"
    ],
    "methods": {
      "zscore": {
        "national": 2.5,
        "dma_pairs": 1.5,
        "census_blocks": 3.0,
        "note": "DOW-partitioned rolling windows with TIERED fallback (28d\u219214d\u21924d)"
      },
      "percentage_spike": {
        "threshold": 30,
        "note": "30% increase over baseline"
      },
      "first_appearance": {
        "level": "DMA (winner, loser, dma) - not census block",
        "note": "New blocks appear daily, DMA level more stable"
      },
      "rare_pairs": {
        "threshold": 5,
        "note": "Appearance rank <= 5"
      },
      "minimum_volume": {
        "daily": 5,
        "note": "Ignore pairs with < 5 wins on target date"
      }
    },
    "windows": {
      "tiered_thresholds": {
        "preferred": "28 preceding days (needs 4+ DOW periods for weekday, 2+ for weekend)",
        "fallback_1": "14 preceding days (needs 4+ DOW periods for weekday, 2+ for weekend)",
        "fallback_2": "4 preceding days (needs 4+ DOW periods for weekday, 2+ for weekend)",
        "note": "DOW partitioning prevents false positives from weekend spikes",
        "implementation": "Tiered logic in scan_base_outliers() - selects best available window"
      },
      "weekday": "28d, 14d, or 4d based on availability (minimum 4 DOW periods)",
      "weekend": "28d, 14d, or 4d based on availability (minimum 2 DOW periods - more lenient)",
      "architectural_insight": "Calculate rolling metrics over ENTIRE time series, then filter to graph window at the end"
    }
  },
  "suppression_workflow": {
    "main_py_steps": [
      "0. Preview base graph - Unsuppressed national shares",
      "1. Scan outliers - Detect national-level anomalies",
      "2. Build plan - Generate auto + distributed suppression",
      "3. Save plan - Store to database and CSV",
      "4. Build dataset - Apply to files (optional)",
      "5. Preview graph - Before/after comparison"
    ],
    "distribution_algorithm": {
      "stage_1_auto": {
        "triggers": [
          "pair_outlier_pos (z-score)",
          "pct_outlier_pos (30% spike)",
          "rare_pair (appearance_rank <= 5)",
          "new_pair (first appearance)"
        ],
        "removal": "Excess over baseline (surgical)",
        "minimum": "5 wins per day"
      },
      "stage_2_distributed": {
        "when": "Stage 1 doesn't reach target",
        "method": "Even distribution across all pairs",
        "caps": "Respects pair capacity (can't remove more than exists)",
        "goal": "No single DMA bears full burden"
      }
    },
    "top_50_filter": {
      "scope": "Total wins over entire time series",
      "egregious_threshold": 40,
      "note": "Focus on top 50, but flag outliers with 40+ impact outside"
    }
  },
  "performance": {
    "cube_queries": "< 1 second",
    "rolling_view_queries": "< 2 seconds",
    "enriched_view_creation": "2-5 seconds (filtered to window)",
    "full_workflow": "< 30 seconds scan to preview",
    "note": "100x+ faster than parquet scanning"
  },
  "key_functions": {
    "tools.db": {
      "get_db_path()": "Returns canonical DB path with assertion",
      "query(sql, db_path)": "Execute SQL, return DataFrame",
      "get_connection(db_path)": "Get DuckDB connection with assertion"
    },
    "tools.src.metrics": {
      "national_timeseries()": "Win share time series",
      "pair_metrics()": "Winner-loser pair analysis",
      "competitor_view()": "H2H competitive landscape"
    },
    "tools.src.outliers": {
      "national_outliers()": "DOW-aware z-score detection",
      "cube_outliers()": "Query pre-computed outlier flags"
    },
    "tools.src.plan": {
      "base_national_series()": "Get national shares (DB-backed)",
      "scan_base_outliers()": "Scan for outliers (rolling views)",
      "build_enriched_cube()": "Create UI-ready enriched view",
      "get_top_50_carriers()": "Filter to top 50 by wins"
    }
  },
  "main_py_restoration": {
    "status": "Phase 2 COMPLETE \u2705",
    "completed_date": "2025-10-05",
    "phases": {
      "phase_1": {
        "status": "COMPLETE",
        "date": "2025-10-04",
        "changes": "Migrated tools/src/plan.py from parquet to database queries"
      },
      "phase_2": {
        "status": "COMPLETE",
        "date": "2025-10-05",
        "changes": [
          "Updated main.py to use database-backed functions",
          "Implemented 5-step workflow (preview, scan, plan, save, compare)",
          "Added auto + distributed suppression algorithm",
          "Added outlier visualization graph in Step 1",
          "CSV save working, database persistence TODO"
        ],
        "testing_guide": "analysis/TESTING_GUIDE.md"
      }
    },
    "what_works": {
      "step_0": "Preview base graph - national win share from cubes",
      "step_1": "Scan outliers - DOW-aware rolling metrics + visualization graph",
      "step_2": "Build plan - auto + distributed algorithm (NO 50% cap)",
      "step_3": "Save plan - CSV working (database TODO)",
      "step_5": "Preview before/after - overlay graph with solid/dashed lines"
    },
    "key_features": {
      "outlier_detection": {
        "auto_stage_triggers": [
          "pair_outlier_pos (z-score > 1.5)",
          "pct_outlier_pos (30% spike)",
          "rare_pair (IF z-score > 1.5 AND impact > 15)",
          "new_pair (first appearance at DMA level)"
        ],
        "removal_amount": "FULL excess (current - baseline), NO 50% CAP",
        "distributed_stage": "Fair allocation across all pairs"
      },
      "configurable_params": {
        "z_threshold": "Slider 0.5-5.0 (default: 2.5)",
        "top_n": "Slider 10-100 (default: 50)",
        "egregious_threshold": "Slider 10-100 (default: 40)"
      },
      "graphs": {
        "step_0": "Base national win share line chart",
        "step_1": "Time series with X markers on outlier dates",
        "step_5": "Overlay: solid=base, dashed=suppressed"
      }
    },
    "next_steps": [
      "User testing and validation",
      "Database persistence for suppressions schema",
      "Integration with carrier_suppression_dashboard.py",
      "Census block precision (future enhancement)"
    ]
  },
  "common_mistakes": {
    "multiple_databases": "NEVER create .db files outside data/databases/",
    "temp_files_in_root": "ALWAYS use analysis/ subdirectories",
    "dow_confusion": "DuckDB DAYOFWEEK: 1=Sunday, strftime('%w'): 0=Sunday",
    "missing_assertion": "ALWAYS assert db_path before connection",
    "csv_only": "Save to BOTH database AND CSV for compatibility",
    "nan_to_integer": "ALWAYS check for NULL AND NaN before CAST(...AS INTEGER) - use: WHEN col IS NOT NULL AND NOT isnan(col) THEN CAST(...)",
    "rolling_metrics_null": "Early dates have NULL rolling metrics - TIERED approach reduces this (28d\u219214d\u21924d)",
    "tiered_window_handling": "Use selected_window column to see which tier was used; filter WHERE selected_window IS NOT NULL to exclude early dates",
    "rolling_view_columns": "Rolling views use: avg_wins, stddev_wins, n_periods, selected_window (NOT avg_wins_28d, n_periods_28d)",
    "scan_base_outliers_implementation": "\u2705 CORRECT: Calculates rolling metrics over ENTIRE time series, filters to graph window at end (line 295). Always check WHERE clause is at final SELECT.",
    "nan_handling": "\u2705 FIXED: All CAST operations now check: WHEN col IS NOT NULL AND NOT isnan(col) THEN CAST(...) ELSE 0/NULL"
  },
  "git_workflow": {
    "branch": "codex-agent",
    "commit_style": "<type>(scope): description",
    "validation": "Get user approval before proceeding to next phase",
    "testing": "Test each change immediately after implementation"
  },
  "analysis_workflow": {
    "output_location": "analysis/{analysis_name}/",
    "subdirs": {
      "images": "analysis/{name}/images/",
      "outputs": "analysis/{name}/outputs/",
      "reports": "analysis/{name}/*.md"
    },
    "cleanup": "Remove temp files, keep final reports in docs/",
    "vector_db": "Update .agent_memory.json after each major analysis"
  }
}